/**
 * Import Service - Vendor CSV Import Business Logic
 *
 * This service handles operational imports of vendor CSV data (e.g., Tenable vulnerability scans),
 * not backup/restore operations. Those are handled by the backup service.
 *
 * Business logic extracted from server.js lines: 252-341, 1306-1823, 2291-2335, and various processing functions
 *
 * INTEGRATION DEPENDENCIES FOR T053:
 * ==================================
 * - Uses DatabaseService for all database operations
 * - Uses PathValidator for secure file operations
 * - Uses helpers for vulnerability mapping and deduplication
 * - Requires existing database schema (staging tables, current tables)
 * - Compatible with existing ProgressTracker WebSocket implementation
 * - Maintains all existing CSV parsing and mapping logic
 */

const Papa = require("papaparse");
const crypto = require("crypto");
const PathValidator = require("../utils/PathValidator");
const DatabaseService = require("./databaseService");
const ValidationService = require("./validationService");
const helpers = require("../utils/helpers");

/**
 * Extract scan date from filename using various patterns
 * From server.js lines 2291-2335
 */
function extractDateFromFilename(filename) {
    if (!filename) {
        return null;
    }

    const currentYear = new Date().getFullYear();

    // Pattern 1: Month abbreviations (aug28, sept01, etc.)
    const monthAbbrMatch = filename.match(/(jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)(\d{1,2})/i);
    if (monthAbbrMatch) {
        const monthMap = {
            "jan": "01", "feb": "02", "mar": "03", "apr": "04", "may": "05", "jun": "06",
            "jul": "07", "aug": "08", "sep": "09", "sept": "09", "oct": "10", "nov": "11", "dec": "12"
        };
        const month = monthMap[monthAbbrMatch[1].toLowerCase()];
        const day = monthAbbrMatch[2].padStart(2, "0");
        return `${currentYear}-${month}-${day}`;
    }

    // Pattern 2: MM_DD_YYYY or MM-DD-YYYY format
    const numericDateMatch = filename.match(/(\d{1,2})[_-](\d{1,2})[_-](\d{4})/);
    if (numericDateMatch) {
        const month = numericDateMatch[1].padStart(2, "0");
        const day = numericDateMatch[2].padStart(2, "0");
        const year = numericDateMatch[3];
        return `${year}-${month}-${day}`;
    }

    // Pattern 3: YYYY-MM-DD format
    const isoDateMatch = filename.match(/(\d{4})[_-](\d{1,2})[_-](\d{1,2})/);
    if (isoDateMatch) {
        const year = isoDateMatch[1];
        const month = isoDateMatch[2].padStart(2, "0");
        const day = isoDateMatch[3].padStart(2, "0");
        return `${year}-${month}-${day}`;
    }

    // Pattern 4: Just day number (assume current month/year)
    const dayOnlyMatch = filename.match(/(\d{1,2})[^\d]/);
    if (dayOnlyMatch) {
        const day = dayOnlyMatch[1].padStart(2, "0");
        const month = String(new Date().getMonth() + 1).padStart(2, "0");
        return `${currentYear}-${month}-${day}`;
    }

    return null; // No date pattern found
}

/**
 * Extract vendor from filename based on common patterns
 */
function extractVendorFromFilename(filename) {
    if (!filename) {
        return "unknown";
    }

    const lowerFilename = filename.toLowerCase();

    // Check for common vendor patterns
    if (lowerFilename.includes("tenable") || lowerFilename.includes("nessus")) {
        return "Tenable";
    }
    if (lowerFilename.includes("qualys")) {
        return "Qualys";
    }
    if (lowerFilename.includes("rapid7") || lowerFilename.includes("nexpose")) {
        return "Rapid7";
    }
    if (lowerFilename.includes("openvas")) {
        return "OpenVAS";
    }
    if (lowerFilename.includes("nmap")) {
        return "Nmap";
    }

    return "unknown";
}

/**
 * Map CSV row to vulnerability record(s) with multi-CVE splitting
 * From server.js lines 252-341
 */
function mapVulnerabilityRow(row) {
    // CVE extraction logic - try direct field first, then extract from name
    let cve = row["definition.cve"] || row["cve"] || row["CVE"] || "";
    if (!cve && row["definition.name"]) {
        const cveMatch = row["definition.name"].match(/(CVE-\d{4}-\d+)/);
        cve = cveMatch ? cveMatch[1] : "";

        // Also try extracting Cisco vulnerability IDs from parentheses
        if (!cve) {
            const ciscoMatch = row["definition.name"].match(/\(([^)]+)\)$/);
            cve = ciscoMatch ? ciscoMatch[1] : "";
        }
    }

    // Enhanced hostname processing with normalization
    let hostname = row["asset.name"] || row["hostname"] || row["Host"] || "";
    hostname = helpers.normalizeHostname(hostname);

    // Enhanced IP address handling for multiple formats
    let ipAddress = row["asset.display_ipv4_address"] || row["asset.ipv4_addresses"] || row["ip_address"] || row["IP Address"] || "";
    if (ipAddress && ipAddress.includes(",")) {
        // Take first valid IP from comma-separated list
        const ips = ipAddress.split(",").map(ip => ip.trim());
        ipAddress = ips[0]; // Use first IP as primary
    }

    // Enhanced description handling - prefer definition.description for Tenable, name for others
    const description = row["definition.description"] || row["definition.name"] || row["plugin_name"] || row["description"] || row["Description"] || "";

    // Plugin name contains the full vulnerability name/description for matching and display
    const pluginName = row["definition.name"] || row["plugin_name"] || row["description"] || row["Description"] || "";

    // Parse multiple CVEs and create separate records for each
    const cvePattern = /CVE-\d{4}-\d{4,}/gi;
    const ciscoPattern = /cisco-sa-[\w-]+/gi;

    const cveMatches = (cve || "").match(cvePattern) || [];
    const ciscoMatches = (cve || "").match(ciscoPattern) || [];
    const allCVEs = [...cveMatches, ...ciscoMatches];

    // If no CVEs found, create single record with empty CVE
    if (allCVEs.length === 0) {
        return [{
            assetId: row["asset.id"] || row["asset_id"] || row["Asset ID"] || "",
            hostname: hostname,
            ipAddress: ipAddress,
            cve: "",
            severity: row["severity"] || row["Severity"] || "",
            vprScore: (() => {
                const vprValue = row["definition.vpr.score"] || row["definition.vpr_v2.score"] || row["vpr_score"] || row["VPR Score"];
                if (vprValue !== undefined && vprValue !== null && vprValue !== '') {
                    const parsed = parseFloat(vprValue);
                    return isNaN(parsed) ? null : parsed;
                }
                return null;
            })(),
            cvssScore: row["cvss_score"] || row["CVSS Score"] ? parseFloat(row["cvss_score"] || row["CVSS Score"]) : null,
            vendor: helpers.normalizeVendor(row["definition.family"] || row["vendor"] || row["Vendor"] || ""),
            pluginName: pluginName,
            description: description,
            solution: row["solution"] || row["Solution"] || "",
            state: row["state"] || row["State"] || "ACTIVE",
            firstSeen: row["first_seen"] || row["First Seen"] || "",
            lastSeen: row["last_seen"] || row["Last Seen"] || "",
            pluginId: row["definition.id"] || row["plugin_id"] || row["Plugin ID"] || "",
            pluginPublished: row["definition.plugin_published"] || row["definition.plugin_updated"] || row["definition.vulnerability_published"] || row["vulnerability_date"] || row["plugin_published"] || ""
        }];
    }

    // Create separate record for each CVE
    return allCVEs.map(individualCVE => {
        // Augment description with CVE if not already present
        let augmentedDescription = description;
        if (description && !description.includes(individualCVE)) {
            augmentedDescription = `${description} (${individualCVE})`;
        }

        return {
            assetId: row["asset.id"] || row["asset_id"] || row["Asset ID"] || "",
            hostname: hostname,
            ipAddress: ipAddress,
            cve: individualCVE,
            severity: row["severity"] || row["Severity"] || "",
            vprScore: (() => {
                const vprValue = row["definition.vpr.score"] || row["definition.vpr_v2.score"] || row["vpr_score"] || row["VPR Score"];
                if (vprValue !== undefined && vprValue !== null && vprValue !== '') {
                    const parsed = parseFloat(vprValue);
                    return isNaN(parsed) ? null : parsed;
                }
                return null;
            })(),
            cvssScore: row["cvss_score"] || row["CVSS Score"] ? parseFloat(row["cvss_score"] || row["CVSS Score"]) : null,
            vendor: helpers.normalizeVendor(row["definition.family"] || row["vendor"] || row["Vendor"] || ""),
            pluginName: pluginName,
            description: augmentedDescription,
            solution: row["solution"] || row["Solution"] || "",
            state: row["state"] || row["State"] || "ACTIVE",
            firstSeen: row["first_seen"] || row["First Seen"] || "",
            lastSeen: row["last_seen"] || row["Last Seen"] || "",
            pluginId: row["definition.id"] || row["plugin_id"] || row["Plugin ID"] || "",
            pluginPublished: row["definition.plugin_published"] || row["definition.plugin_updated"] || row["definition.vulnerability_published"] || row["vulnerability_date"] || row["plugin_published"] || ""
        };
    });
}

/**
 * Parse CSV file using PapaParse
 */
async function parseCSV(csvData) {
    return new Promise((resolve, reject) => {
        Papa.parse(csvData, {
            header: true,
            skipEmptyLines: true,
            complete: (results) => resolve(results),
            error: (error) => reject(error)
        });
    });
}

/**
 * Create import record in database
 */
async function createImportRecord({ filename, vendor, scanDate, rowCount, fileSize, headers }) {
    return new Promise((resolve, reject) => {
        const importDate = new Date().toISOString();

        const importQuery = `
            INSERT INTO vulnerability_imports
            (filename, import_date, row_count, vendor, file_size, processing_time, raw_headers)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        `;

        const db = global.db;
        db.run(importQuery, [
            filename,
            importDate,
            rowCount,
            vendor,
            fileSize,
            0, // Will update after completion
            JSON.stringify(headers)
        ], function(err) {
            if (err) {
                reject(err);
            } else {
                resolve({
                    importId: this.lastID,
                    importDate
                });
            }
        });
    });
}

/**
 * Process vulnerabilities with enhanced lifecycle management
 * Simplified version of the complex logic from server.js lines 1306+
 */
async function processVulnerabilitiesWithLifecycle(rows, importId, filePath, scanDate) {
    return new Promise((resolve, reject) => {
        const currentDate = scanDate || new Date().toISOString().split("T")[0];
        const db = global.db;

        console.log("ðŸš€ PERFORMANCE: Starting enhanced rollover import");
        console.log(`ðŸ“Š PERFORMANCE: Scan date: ${currentDate}, Rows: ${rows.length}`);

        // Step 1: Mark all active vulnerabilities as potentially stale (grace period)
        db.run("UPDATE vulnerabilities_current SET lifecycle_state = 'grace_period' WHERE lifecycle_state = 'active'", (err) => {
            if (err) {
                console.error("Error marking vulnerabilities as stale:", err);
                reject(new Error("Failed to prepare for import"));
                return;
            }

            // Step 2: Process new vulnerability data
            const stats = {
                inserted: 0,
                updated: 0,
                reopened: 0,
                duplicate_skipped: 0
            };

            let processedRows = 0;
            const totalRecords = rows.reduce((total, row) => total + mapVulnerabilityRow(row).length, 0);

            // Process rows sequentially to prevent race conditions
            function processNextRow(index) {
                if (index >= rows.length) {
                    // Finalize processing
                    finalizeImport();
                    return;
                }

                const row = rows[index];
                const mappedArray = mapVulnerabilityRow(row);

                if (mappedArray.length === 0) {
                    processNextRow(index + 1);
                    return;
                }

                let pendingOperations = 0;
                let completedOperations = 0;

                // Process each mapped vulnerability from this row
                for (const mapped of mappedArray) {
                    pendingOperations++;

                    // Generate unique key for deduplication
                    const uniqueKey = helpers.generateUniqueKey(mapped);

                    // Insert to vulnerabilities table (snapshot)
                    const snapshotQuery = `
                        INSERT INTO vulnerabilities
                        (import_id, hostname, ip_address, cve, severity, vpr_score, cvss_score,
                         first_seen, last_seen, plugin_id, plugin_name, description, solution,
                         vendor, vulnerability_date, state, import_date)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    `;

                    db.run(snapshotQuery, [
                        importId,
                        mapped.hostname,
                        mapped.ipAddress,
                        mapped.cve,
                        mapped.severity,
                        mapped.vprScore,
                        mapped.cvssScore,
                        mapped.firstSeen,
                        mapped.lastSeen,
                        mapped.pluginId,
                        mapped.pluginName,
                        mapped.description,
                        mapped.solution,
                        mapped.vendor,
                        mapped.pluginPublished,
                        mapped.state,
                        currentDate
                    ], function(snapshotErr) {
                        if (snapshotErr) {
                            console.error("Error inserting to vulnerabilities:", snapshotErr);
                        }

                        // Check if vulnerability exists in current table
                        db.get("SELECT * FROM vulnerabilities_current WHERE unique_key = ?", [uniqueKey], (currentErr, existing) => {
                            if (currentErr) {
                                console.error("Error checking current vulnerability:", currentErr);
                            } else if (existing) {
                                // Update existing vulnerability
                                db.run(`
                                    UPDATE vulnerabilities_current
                                    SET lifecycle_state = 'active', last_seen = ?, severity = ?, vpr_score = ?, cvss_score = ?
                                    WHERE unique_key = ?
                                `, [currentDate, mapped.severity, mapped.vprScore, mapped.cvssScore, uniqueKey], (updateErr) => {
                                    if (!updateErr) {stats.updated++;}
                                });
                            } else {
                                // Insert new vulnerability to current table
                                db.run(`
                                    INSERT INTO vulnerabilities_current
                                    (unique_key, hostname, ip_address, cve, severity, vpr_score, cvss_score,
                                     first_seen, last_seen, plugin_id, plugin_name, description, solution,
                                     vendor, vulnerability_date, state, lifecycle_state, import_date)
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                `, [
                                    uniqueKey,
                                    mapped.hostname,
                                    mapped.ipAddress,
                                    mapped.cve,
                                    mapped.severity,
                                    mapped.vprScore,
                                    mapped.cvssScore,
                                    mapped.firstSeen,
                                    currentDate,
                                    mapped.pluginId,
                                    mapped.pluginName,
                                    mapped.description,
                                    mapped.solution,
                                    mapped.vendor,
                                    mapped.pluginPublished,
                                    mapped.state,
                                    "active",
                                    currentDate
                                ], (insertErr) => {
                                    if (!insertErr) {stats.inserted++;}
                                });
                            }

                            completedOperations++;
                            if (completedOperations === pendingOperations) {
                                processedRows++;
                                if (processedRows % 100 === 0) {
                                    console.log(`ðŸ“ˆ PROGRESS: ${processedRows}/${rows.length} rows processed`);
                                }
                                processNextRow(index + 1);
                            }
                        });
                    });
                }
            }

            function finalizeImport() {
                // Mark remaining grace period vulnerabilities as resolved
                db.run("UPDATE vulnerabilities_current SET lifecycle_state = 'resolved' WHERE lifecycle_state = 'grace_period'", (finalErr) => {
                    if (finalErr) {
                        console.error("Error finalizing import:", finalErr);
                        reject(finalErr);
                    } else {
                        console.log("âœ… Enhanced lifecycle import completed:", stats);
                        resolve({
                            success: true,
                            stats,
                            totalRecords,
                            currentDate,
                            enhancedLifecycle: true
                        });
                    }
                });
            }

            // Start processing
            processNextRow(0);
        });
    });
}

/**
 * Process staging import with progress tracking
 * High-performance import using staging table for batch processing
 */
async function processStagingImport({ filePath, filename, vendor, scanDate, sessionId, startTime, progressTracker }) {
    try {
        // Update progress: Starting CSV parsing
        progressTracker.updateProgress(sessionId, 5, "Parsing CSV file...", { currentStep: 1 });

        // Read and parse CSV
        const csvData = PathValidator.safeReadFileSync(filePath, "utf8");
        const results = await parseCSV(csvData);
        const rows = results.data.filter(row => Object.values(row).some(val => val && val.trim()));

        // Update progress: CSV parsing completed
        progressTracker.updateProgress(sessionId, 15, `Parsed ${rows.length} rows from CSV`, {
            currentStep: 1,
            rowCount: rows.length
        });

        console.log(`ðŸ“ˆ Parsed ${rows.length} rows from CSV`);

        // Create import record
        const importRecord = await createImportRecord({
            filename,
            vendor,
            scanDate,
            rowCount: rows.length,
            fileSize: 0, // File size not available in this context
            headers: results.meta.fields
        });

        // Update progress: Starting bulk load to staging
        progressTracker.updateProgress(sessionId, 20, "Loading data to staging table...", {
            currentStep: 2,
            importId: importRecord.importId
        });

        // Bulk load to staging table (simplified version)
        await bulkLoadToStagingTable(rows, importRecord.importId, scanDate, filePath, {
            success: true,
            importId: importRecord.importId,
            filename,
            vendor,
            scanDate,
            stagingMode: true
        }, sessionId, startTime, progressTracker);

    } catch (error) {
        console.error("Staging import failed:", error);
        progressTracker.errorSession(sessionId, "Staging import failed: " + error.message, { error });
        throw error;
    }
}

/**
 * Simplified bulk load to staging table
 */
async function bulkLoadToStagingTable(rows, importId, scanDate, filePath, responseData, sessionId, startTime, progressTracker) {
    return new Promise((resolve, reject) => {
        const db = global.db;
        const loadStart = Date.now();

        console.log(`ðŸš€ BULK LOAD: Starting bulk insert of ${rows.length} rows to staging table`);

        const stagingInsertSQL = `
            INSERT INTO vulnerability_staging (
                import_id, hostname, ip_address, cve, severity, vpr_score, cvss_score,
                plugin_id, plugin_name, description, solution, vendor_reference, vendor,
                vulnerability_date, state, raw_csv_row
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `;

        db.serialize(() => {
            db.run("BEGIN TRANSACTION", (err) => {
                if (err) {
                    console.error("Error starting transaction:", err);
                    if (progressTracker && progressTracker.errorSession) {
                        progressTracker.errorSession(sessionId, "Transaction start failed", { error: err });
                    }
                    reject(err);
                    return;
                }

                console.log("ðŸ’¾ Transaction started - bulk inserting rows");
                if (progressTracker && progressTracker.updateProgress) {
                    progressTracker.updateProgress(sessionId, 25, "Inserting rows into staging table...", { currentStep: 2 });
                }

                const stmt = db.prepare(stagingInsertSQL);
                let insertedCount = 0;
                let errorCount = 0;

                // Process all rows and their mapped vulnerabilities
                const allMappedRecords = [];
                rows.forEach((row, index) => {
                    try {
                        const mappedArray = mapVulnerabilityRow(row);
                        mappedArray.forEach(mapped => {
                            allMappedRecords.push({
                                mapped,
                                sourceRowIndex: index,
                                rawRow: row
                            });
                        });
                    } catch (mappingError) {
                        console.error(`Error mapping row ${index}:`, mappingError);
                        errorCount++;
                    }
                });

                // Insert all mapped records
                allMappedRecords.forEach((record, index) => {
                    try {
                        const mapped = record.mapped;
                        stmt.run([
                            importId,
                            mapped.hostname,
                            mapped.ipAddress,
                            mapped.cve,
                            mapped.severity,
                            mapped.vprScore,
                            mapped.cvssScore,
                            mapped.pluginId,
                            mapped.pluginName,
                            mapped.description,
                            mapped.solution,
                            "", // vendor_reference
                            mapped.vendor,
                            mapped.pluginPublished,
                            mapped.state,
                            JSON.stringify(record.rawRow)
                        ], (err) => {
                            if (err) {
                                console.error(`Error inserting staging record ${index}:`, err);
                                errorCount++;
                            } else {
                                insertedCount++;

                                // Update progress every 100 records
                                if (insertedCount % 100 === 0 || insertedCount === allMappedRecords.length) {
                                    const progress = 25 + ((insertedCount / allMappedRecords.length) * 35); // 25-60% range
                                    if (progressTracker && progressTracker.updateProgress) {
                                        progressTracker.updateProgress(sessionId, progress,
                                            `Inserted ${insertedCount}/${allMappedRecords.length} records to staging table...`, {
                                                currentStep: 2,
                                                insertedCount,
                                                totalRows: allMappedRecords.length
                                            });
                                    }
                                }
                            }
                        });
                    } catch (insertError) {
                        console.error(`Error preparing insert for record ${index}:`, insertError);
                        errorCount++;
                    }
                });

                // Finalize and commit
                stmt.finalize((err) => {
                    if (err) {
                        console.error("Error finalizing statement:", err);
                        db.run("ROLLBACK", () => {
                            if (progressTracker && progressTracker.errorSession) {
                                progressTracker.errorSession(sessionId, "Staging insert failed", { error: err, errorCount });
                            }
                            reject(err);
                        });
                        return;
                    }

                    db.run("COMMIT", (err) => {
                        if (err) {
                            console.error("Error committing transaction:", err);
                            if (progressTracker && progressTracker.errorSession) {
                                progressTracker.errorSession(sessionId, "Transaction commit failed", { error: err });
                            }
                            reject(err);
                            return;
                        }

                        const loadTime = Date.now() - loadStart;
                        const rowsPerSecond = insertedCount / (loadTime / 1000);

                        console.log(`âœ… BULK LOAD COMPLETE: ${insertedCount} records inserted in ${loadTime}ms (${rowsPerSecond.toFixed(1)} records/sec)`);

                        // Update progress: Staging complete
                        if (progressTracker && progressTracker.updateProgress) {
                            progressTracker.updateProgress(sessionId, 60,
                                `Staging complete. Processing ${insertedCount} records to final tables...`, {
                                currentStep: 3,
                                insertedToStaging: insertedCount,
                                loadTime,
                                rowsPerSecond: parseFloat(rowsPerSecond.toFixed(1))
                            });
                        }

                        // Clean up file
                        try {
                            if (filePath && PathValidator.safeExistsSync(filePath)) {
                                PathValidator.safeUnlinkSync(filePath);
                            }
                        } catch (cleanupError) {
                            console.warn("File cleanup warning:", cleanupError.message);
                        }

                        // Now process from staging to final tables
                        processStagingToFinalTables(importId, responseData.scanDate, {
                            ...responseData,
                            bulkLoadTime: loadTime,
                            bulkLoadRowsPerSecond: parseFloat(rowsPerSecond.toFixed(1)),
                            insertedToStaging: insertedCount,
                            stagingErrors: errorCount
                        }, sessionId, startTime, progressTracker, () => {
                            // Complete after processing to final tables
                            resolve({
                                insertedToStaging: insertedCount,
                                stagingErrors: errorCount
                            });
                        });
                    });
                });
            });
        });
    });
}

/**
 * Process staging data to final vulnerability tables with full rollover architecture
 */
function processStagingToFinalTables(importId, scanDate, responseData, sessionId, startTime, progressTracker, callback) {
    const db = global.db;

    console.log("ðŸ”„ Processing staging data to final tables with rollover architecture");
    console.log(`ðŸ“Š Import ID: ${importId}, Scan Date: ${scanDate}`);

    // Update progress
    if (progressTracker && progressTracker.updateProgress) {
        progressTracker.updateProgress(sessionId, 70, "Processing staging data to rollover tables...", { currentStep: 3 });
    }

    // Get all staging records for this import
    db.all("SELECT * FROM vulnerability_staging WHERE import_id = ?", [importId], (err, stagingRows) => {
        if (err) {
            console.error("Error fetching staging data:", err);
            if (progressTracker && progressTracker.errorSession) {
                progressTracker.errorSession(sessionId, "Failed to fetch staging data", { error: err });
            }
            if (callback) callback(err);
            return;
        }

        console.log(`ðŸ“¦ Processing ${stagingRows.length} vulnerabilities from staging`);

        let processed = 0;
        let insertedToSnapshots = 0;
        let insertedToCurrent = 0;
        let updatedInCurrent = 0;
        let errors = 0;

        // Process each row
        const processNextRow = (index) => {
            if (index >= stagingRows.length) {
                // All rows processed, update daily totals
                updateDailyTotals(scanDate, () => {
                    // Clear staging table
                    db.run("DELETE FROM vulnerability_staging WHERE import_id = ?", [importId], (cleanErr) => {
                        if (cleanErr) {
                            console.warn("Warning: Could not clear staging table:", cleanErr);
                        }

                        // Also insert to legacy vulnerabilities table for backward compatibility
                        const legacySQL = `
                            INSERT INTO vulnerabilities (
                                import_id, hostname, ip_address, cve, severity, vpr_score, cvss_score,
                                plugin_id, plugin_name, description, solution, vendor_reference, vendor,
                                vulnerability_date, first_seen, last_seen, state
                            )
                            SELECT
                                import_id, hostname, ip_address, cve, severity, vpr_score, cvss_score,
                                plugin_id, plugin_name, description, solution, vendor_reference, vendor,
                                vulnerability_date, scan_date, scan_date, state
                            FROM vulnerabilities_current
                            WHERE import_id = ?
                        `;

                        db.run(legacySQL, [importId], (legacyErr) => {
                            if (legacyErr) {
                                console.warn("Warning: Could not update legacy table:", legacyErr);
                            }

                            console.log(`âœ… Rollover processing complete:
                                - Snapshots: ${insertedToSnapshots}
                                - Current Inserted: ${insertedToCurrent}
                                - Current Updated: ${updatedInCurrent}
                                - Errors: ${errors}`);

                            // Complete the session
                            if (progressTracker && progressTracker.completeSession) {
                                progressTracker.completeSession(sessionId, "Import completed successfully", {
                                    ...responseData,
                                    processedToFinal: processed,
                                    insertedToSnapshots,
                                    insertedToCurrent,
                                    updatedInCurrent,
                                    totalTime: Date.now() - startTime
                                });
                            }

                            if (callback) callback(null, processed);
                        });
                    });
                });
                return;
            }

            const row = stagingRows[index];
            const uniqueKey = `${row.hostname}_${row.cve}`;

            // 1. Insert into vulnerability_snapshots (historical record)
            const snapshotSQL = `
                INSERT INTO vulnerability_snapshots (
                    import_id, scan_date, hostname, ip_address, cve, severity,
                    vpr_score, cvss_score, first_seen, last_seen, plugin_id,
                    plugin_name, description, solution, vendor_reference, vendor,
                    vulnerability_date, state, unique_key
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            `;

            db.run(snapshotSQL, [
                importId, scanDate, row.hostname, row.ip_address, row.cve, row.severity,
                row.vpr_score, row.cvss_score, scanDate, scanDate, row.plugin_id,
                row.plugin_name, row.description, row.solution, row.vendor_reference, row.vendor,
                row.vulnerability_date, row.state || 'ACTIVE', uniqueKey
            ], (snapErr) => {
                if (snapErr) {
                    console.error(`Snapshot insert error for ${uniqueKey}:`, snapErr);
                    errors++;
                } else {
                    insertedToSnapshots++;
                }

                // 2. Check if exists in vulnerabilities_current
                db.get("SELECT id FROM vulnerabilities_current WHERE unique_key = ?", [uniqueKey], (checkErr, existing) => {
                    if (checkErr) {
                        console.error(`Check existing error for ${uniqueKey}:`, checkErr);
                        errors++;
                        processed++;
                        processNextRow(index + 1);
                    } else if (existing) {
                        // Update existing in current
                        const updateSQL = `
                            UPDATE vulnerabilities_current SET
                                import_id = ?, scan_date = ?, ip_address = ?, severity = ?,
                                vpr_score = ?, cvss_score = ?, last_seen = ?, plugin_id = ?,
                                plugin_name = ?, description = ?, solution = ?, vendor_reference = ?,
                                vendor = ?, vulnerability_date = ?, state = ?, lifecycle_state = 'active'
                            WHERE id = ?
                        `;

                        db.run(updateSQL, [
                            importId, scanDate, row.ip_address, row.severity,
                            row.vpr_score, row.cvss_score, scanDate, row.plugin_id,
                            row.plugin_name, row.description, row.solution, row.vendor_reference,
                            row.vendor, row.vulnerability_date, row.state || 'ACTIVE', existing.id
                        ], (updateErr) => {
                            if (updateErr) {
                                console.error(`Update error for ${uniqueKey}:`, updateErr);
                                errors++;
                            } else {
                                updatedInCurrent++;
                            }
                            processed++;
                            processNextRow(index + 1);
                        });
                    } else {
                        // Insert new into current
                        const insertSQL = `
                            INSERT INTO vulnerabilities_current (
                                import_id, scan_date, hostname, ip_address, cve, severity,
                                vpr_score, cvss_score, first_seen, last_seen, plugin_id,
                                plugin_name, description, solution, vendor_reference, vendor,
                                vulnerability_date, state, unique_key, lifecycle_state
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'active')
                        `;

                        db.run(insertSQL, [
                            importId, scanDate, row.hostname, row.ip_address, row.cve, row.severity,
                            row.vpr_score, row.cvss_score, scanDate, scanDate, row.plugin_id,
                            row.plugin_name, row.description, row.solution, row.vendor_reference, row.vendor,
                            row.vulnerability_date, row.state || 'ACTIVE', uniqueKey
                        ], (insertErr) => {
                            if (insertErr) {
                                console.error(`Insert error for ${uniqueKey}:`, insertErr);
                                errors++;
                            } else {
                                insertedToCurrent++;
                            }
                            processed++;
                            processNextRow(index + 1);
                        });
                    }
                });
            });
        };

        // Start processing rows
        processNextRow(0);
    });
}

/**
 * Update vulnerability daily totals for statistics
 */
function updateDailyTotals(scanDate, callback) {
    const db = global.db;

    // Delete existing entry for this date
    db.run("DELETE FROM vulnerability_daily_totals WHERE scan_date = ?", [scanDate], (delErr) => {
        if (delErr) {
            console.warn("Warning: Could not clear daily totals:", delErr);
        }

        // Insert new totals with deduplicated VPR aggregation
        // Group by hostname + plugin_id (or description) to avoid counting multi-CVE vulnerabilities multiple times
        const totalsSQL = `
            INSERT INTO vulnerability_daily_totals (
                scan_date, critical_count, critical_total_vpr, high_count, high_total_vpr,
                medium_count, medium_total_vpr, low_count, low_total_vpr,
                total_vulnerabilities, total_vpr, resolved_count, reopened_count
            )
            SELECT
                ? as scan_date,
                SUM(CASE WHEN severity = 'Critical' THEN vuln_count ELSE 0 END),
                SUM(CASE WHEN severity = 'Critical' THEN max_vpr ELSE 0 END),
                SUM(CASE WHEN severity = 'High' THEN vuln_count ELSE 0 END),
                SUM(CASE WHEN severity = 'High' THEN max_vpr ELSE 0 END),
                SUM(CASE WHEN severity = 'Medium' THEN vuln_count ELSE 0 END),
                SUM(CASE WHEN severity = 'Medium' THEN max_vpr ELSE 0 END),
                SUM(CASE WHEN severity = 'Low' THEN vuln_count ELSE 0 END),
                SUM(CASE WHEN severity = 'Low' THEN max_vpr ELSE 0 END),
                SUM(vuln_count), SUM(max_vpr), 0, 0
            FROM (
                SELECT
                    severity,
                    hostname,
                    COALESCE(plugin_id, SUBSTR(description, 1, 100)) as dedup_key,
                    COUNT(*) as vuln_count,
                    MAX(vpr_score) as max_vpr
                FROM vulnerabilities_current
                WHERE lifecycle_state = 'active'
                GROUP BY severity, hostname, dedup_key
            )
        `;

        db.run(totalsSQL, [scanDate], (insertErr) => {
            if (insertErr) {
                console.warn("Warning: Could not update daily totals:", insertErr);
            } else {
                console.log(`ðŸ“Š Updated daily totals for ${scanDate}`);
            }
            if (callback) callback();
        });
    });
}

/**
 * Process JSON vulnerability data
 */
async function processVulnerabilitiesJSON(csvData) {
    return new Promise((resolve, reject) => {
        const importDate = new Date().toISOString();
        let imported = 0;
        const errors = [];

        // Create import record
        createImportRecord({
            filename: "web-upload.csv",
            vendor: "web-import",
            scanDate: importDate.split("T")[0],
            rowCount: csvData.length,
            fileSize: 0,
            headers: Object.keys(csvData[0] || {})
        }).then(importRecord => {
            const db = global.db;

            // Prepare insert statement
            const stmt = db.prepare(`
                INSERT INTO vulnerabilities
                (import_id, hostname, ip_address, cve, severity, vpr_score, cvss_score,
                 first_seen, last_seen, plugin_id, plugin_name, description, solution,
                 vendor, vulnerability_date, state, import_date)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            `);

            csvData.forEach((row, index) => {
                try {
                    // Map CSV columns to database fields
                    const hostname = row["asset.name"] || row["hostname"] || row["Host"] || "";
                    const ipAddress = row["asset.display_ipv4_address"] || row["asset.ipv4_addresses"] || row["ip_address"] || row["IP Address"] || "";
                    const cve = row["definition.cve"] || row["cve"] || row["CVE"] || "";
                    const severity = row["severity"] || row["Severity"] || "";
                    const vprScore = parseFloat(row["definition.vpr.score"] || row["vpr_score"] || row["VPR Score"] || 0);
                    const cvssScore = parseFloat(row["cvss_score"] || row["CVSS Score"] || 0);
                    const vendor = row["definition.family"] || row["vendor"] || row["Vendor"] || "";
                    const description = row["definition.name"] || row["plugin_name"] || row["description"] || row["Description"] || "";
                    const pluginPublished = row["definition.plugin_published"] || row["vulnerability_date"] || row["plugin_published"] || "";
                    const state = row["state"] || row["State"] || "open";

                    stmt.run([
                        importRecord.importId,
                        hostname,
                        ipAddress,
                        cve,
                        severity,
                        vprScore || null,
                        cvssScore || null,
                        row["first_seen"] || row["First Seen"] || "",
                        row["last_seen"] || row["Last Seen"] || "",
                        row["plugin_id"] || row["Plugin ID"] || "",
                        description,
                        row["description"] || row["Description"] || "",
                        row["solution"] || row["Solution"] || "",
                        vendor,
                        pluginPublished,
                        state,
                        importDate.split("T")[0]
                    ], (err) => {
                        if (err) {
                            console.error(`Error importing vulnerability row ${index + 1}:`, err);
                            errors.push(`Row ${index + 1}: ${err.message}`);
                        } else {
                            imported++;
                        }
                    });
                } catch (error) {
                    errors.push(`Row ${index + 1}: ${error.message}`);
                }
            });

            stmt.finalize((err) => {
                if (err) {
                    console.error("Error finalizing vulnerability import:", err);
                    reject(new Error("Import failed"));
                } else {
                    resolve({
                        imported,
                        importId: importRecord.importId,
                        errors
                    });
                }
            });
        }).catch(reject);
    });
}

/**
 * Process JSON ticket data
 */
async function processTicketsJSON(csvData) {
    return new Promise((resolve, reject) => {
        const db = global.db;
        let imported = 0;
        const errors = [];

        // Prepare insert statement
        const stmt = db.prepare(`
            INSERT INTO tickets
            (title, description, priority, status, assigned_to, category,
             devices, environment, business_impact, technical_details,
             estimated_hours, created_at, due_date)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `);

        csvData.forEach((row, index) => {
            try {
                // Parse devices JSON if it's a string
                let devices = [];
                if (row.devices) {
                    try {
                        devices = typeof row.devices === "string" ? JSON.parse(row.devices) : row.devices;
                    } catch (parseError) {
                        devices = [row.devices]; // Fallback to array with string
                    }
                }

                stmt.run([
                    row.title || "",
                    row.description || "",
                    row.priority || "Medium",
                    row.status || "Open",
                    row.assigned_to || "",
                    row.category || "",
                    JSON.stringify(devices),
                    row.environment || "",
                    row.business_impact || "",
                    row.technical_details || "",
                    parseFloat(row.estimated_hours || 0),
                    row.created_at || new Date().toISOString(),
                    row.due_date || ""
                ], (err) => {
                    if (err) {
                        console.error(`Error importing ticket row ${index + 1}:`, err);
                        errors.push(`Row ${index + 1}: ${err.message}`);
                    } else {
                        imported++;
                    }
                });
            } catch (error) {
                errors.push(`Row ${index + 1}: ${error.message}`);
            }
        });

        stmt.finalize((err) => {
            if (err) {
                console.error("Error finalizing ticket import:", err);
                reject(new Error("Import failed"));
            } else {
                resolve({
                    imported,
                    errors
                });
            }
        });
    });
}

/**
 * Get import history with vulnerability counts
 */
async function getImportHistory() {
    return new Promise((resolve, reject) => {
        const db = global.db;

        const query = `
            SELECT
                vi.*,
                COUNT(v.id) as vulnerability_count
            FROM vulnerability_imports vi
            LEFT JOIN vulnerabilities v ON vi.id = v.import_id
            GROUP BY vi.id
            ORDER BY vi.import_date DESC
            LIMIT 50
        `;

        db.all(query, [], (err, rows) => {
            if (err) {
                reject(err);
            } else {
                resolve(rows);
            }
        });
    });
}

module.exports = {
    extractDateFromFilename,
    extractVendorFromFilename,
    mapVulnerabilityRow,
    parseCSV,
    createImportRecord,
    processVulnerabilitiesWithLifecycle,
    processStagingImport,
    processVulnerabilitiesJSON,
    processTicketsJSON,
    getImportHistory,
    bulkLoadToStagingTable,
    // Alias for compatibility
    extractScanDateFromFilename: extractDateFromFilename
};