# Vulnerability Import Feature Specification

## Purpose

Enable network administrators to import vulnerability scan data from CSV files with intelligent deduplication, historical comparison, and rollover logic to maintain accurate, current vulnerability state.

## Success Criteria

- **CSV Import Success**: 95%+ successful import rate for well-formed scanner CSV files
- **Deduplication Accuracy**: 99%+ accuracy in identifying duplicate vulnerabilities
- **Rollover Performance**: Complete rollover analysis within 30 seconds for 10,000+ records
- **Data Integrity**: Zero data corruption during import process
- **User Experience**: Clear feedback on import progress and results

## User Story

"As a network administrator, I want to upload vulnerability scan CSV files and have the system automatically identify new, persistent, and resolved vulnerabilities so that I can focus on the most critical security issues without manually comparing scan results."

## Requirements

### Functional Requirements

1. **CSV File Processing**:
   - Support multiple CSV formats (Tenable, Qualys, OpenVAS, custom)
   - Handle files up to 100MB (configurable via multer)
   - Parse CSV with Papa Parse for robust handling
   - Validate required columns and data formats

2. **Data Normalization**:
   - Normalize hostnames (remove domains, standardize format)
   - Standardize severity levels (Critical, High, Medium, Low, Info)
   - Parse and validate CVE identifiers
   - Handle missing or malformed data gracefully

3. **Deduplication Logic**:
   - Primary key: `normalizedHostname + CVE`
   - Fallback key: `normalizedHostname + plugin_id + description_hash`
   - Handle edge cases where multiple keys might match
   - Preserve original scanner metadata

4. **Rollover Analysis**:
   - Compare new import against current active vulnerabilities
   - Classify vulnerabilities as: NEW, PERSISTENT, RESOLVED, UPDATED
   - Update vulnerability status and timestamps
   - Maintain historical audit trail

5. **Database Operations**:
   - Sequential processing to prevent race conditions
   - Atomic transactions for data consistency
   - Automatic backup before major changes
   - Schema evolution support for new fields

### Non-Functional Requirements

- **Performance**: Process 10,000 records in <30 seconds
- **Memory Usage**: Stay within 512MB for large imports
- **Reliability**: 99.9% success rate for valid data
- **Scalability**: Support up to 100,000 vulnerability records
- **Usability**: Progress indicators and clear error messages

## Implementation Details

### CSV Upload Interface

```javascript
// File upload handling
const multer = require('multer');
const upload = multer({
  dest: 'uploads/',
  limits: { fileSize: 100 * 1024 * 1024 }, // 100MB
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'text/csv' || file.originalname.endsWith('.csv')) {
      cb(null, true);
    } else {
      cb(new Error('Only CSV files allowed'), false);
    }
  }
});

// API endpoint
app.post('/api/vulnerabilities/import', upload.single('csvFile'), async (req, res) => {
  try {
    const results = await processVulnerabilityImport(req.file);
    res.json({ success: true, results });
  } catch (error) {
    res.status(500).json({ success: false, error: error.message });
  }
});
```

### Data Processing Pipeline

```javascript
async function processVulnerabilityImport(file) {
  const startTime = Date.now();
  
  // Step 1: Parse CSV file
  const csvData = await parseCsvFile(file.path);
  
  // Step 2: Validate and normalize data
  const validationResults = await validateAndNormalizeData(csvData);
  
  // Step 3: Generate deduplication keys
  const keyedData = validationResults.validRows.map(generateDedupKeys);
  
  // Step 4: Perform rollover analysis
  const rolloverResults = await performRolloverAnalysis(keyedData);
  
  // Step 5: Update database (sequential to prevent conflicts)
  const updateResults = await updateDatabaseSequentially(rolloverResults);
  
  // Step 6: Generate import summary
  const summary = generateImportSummary(updateResults, startTime);
  
  // Step 7: Cleanup temporary files
  await fs.unlink(file.path);
  
  // Step 8: Broadcast data update events
  eventBus.publish(EVENTS.DATA_IMPORTED, summary);
  
  return summary;
}
```

### Deduplication Algorithm

```javascript
function generateDedupKeys(vulnerability) {
  const normalized = {
    hostname: normalizeHostname(vulnerability.hostname),
    cve: vulnerability.cve?.trim() || null,
    pluginId: vulnerability.plugin_id?.trim() || null,
    description: vulnerability.description?.trim() || ''
  };
  
  // Primary deduplication key: hostname + CVE
  if (normalized.cve) {
    return {
      ...vulnerability,
      dedupKey: `${normalized.hostname}|${normalized.cve}`,
      keyType: 'hostname_cve',
      normalizedHostname: normalized.hostname
    };
  }
  
  // Fallback key: hostname + plugin_id + description hash
  const descriptionHash = hashString(normalized.description.substring(0, 100));
  return {
    ...vulnerability,
    dedupKey: `${normalized.hostname}|${normalized.pluginId}|${descriptionHash}`,
    keyType: 'hostname_plugin_desc',
    normalizedHostname: normalized.hostname
  };
}

function normalizeHostname(hostname) {
  if (!hostname) return '';
  
  return hostname
    .toLowerCase()
    .split('.')[0] // Remove domain suffix
    .replace(/[^a-z0-9-]/g, '-') // Replace invalid chars with hyphens
    .replace(/-+/g, '-') // Collapse multiple hyphens
    .replace(/^-|-$/g, ''); // Remove leading/trailing hyphens
}
```

### Rollover Analysis Logic

```javascript
async function performRolloverAnalysis(newData) {
  // Load current active vulnerabilities
  const currentVulns = await db.all(
    'SELECT * FROM vulnerabilities_current WHERE status = "ACTIVE"'
  );
  
  // Create maps for efficient lookup
  const currentMap = new Map(currentVulns.map(v => [v.dedupKey, v]));
  const newMap = new Map(newData.map(v => [v.dedupKey, v]));
  
  const results = {
    new: [],
    persistent: [],
    resolved: [],
    updated: []
  };
  
  // Analyze new data
  for (const [key, newVuln] of newMap) {
    const existing = currentMap.get(key);
    
    if (!existing) {
      // New vulnerability
      results.new.push({
        ...newVuln,
        status: 'NEW',
        firstSeen: new Date().toISOString(),
        lastSeen: new Date().toISOString()
      });
    } else if (hasSignificantChanges(existing, newVuln)) {
      // Updated vulnerability
      results.updated.push({
        ...newVuln,
        id: existing.id,
        status: 'UPDATED',
        firstSeen: existing.firstSeen,
        lastSeen: new Date().toISOString(),
        previousSeverity: existing.severity
      });
    } else {
      // Persistent vulnerability
      results.persistent.push({
        ...existing,
        lastSeen: new Date().toISOString(),
        status: 'PERSISTENT'
      });
    }
  }
  
  // Find resolved vulnerabilities
  for (const [key, existing] of currentMap) {
    if (!newMap.has(key)) {
      results.resolved.push({
        ...existing,
        status: 'RESOLVED',
        resolvedDate: new Date().toISOString()
      });
    }
  }
  
  return results;
}
```

### Database Update Strategy

```javascript
async function updateDatabaseSequentially(rolloverResults) {
  const updateSummary = {
    new: 0,
    updated: 0,
    resolved: 0,
    errors: []
  };
  
  // Begin transaction for atomicity
  await db.run('BEGIN TRANSACTION');
  
  try {
    // Process new vulnerabilities
    for (const vuln of rolloverResults.new) {
      try {
        await insertNewVulnerability(vuln);
        updateSummary.new++;
      } catch (error) {
        updateSummary.errors.push({ type: 'insert', vuln: vuln.dedupKey, error: error.message });
      }
    }
    
    // Process updated vulnerabilities
    for (const vuln of rolloverResults.updated) {
      try {
        await updateExistingVulnerability(vuln);
        updateSummary.updated++;
      } catch (error) {
        updateSummary.errors.push({ type: 'update', vuln: vuln.dedupKey, error: error.message });
      }
    }
    
    // Process resolved vulnerabilities
    for (const vuln of rolloverResults.resolved) {
      try {
        await markVulnerabilityResolved(vuln);
        updateSummary.resolved++;
      } catch (error) {
        updateSummary.errors.push({ type: 'resolve', vuln: vuln.dedupKey, error: error.message });
      }
    }
    
    // Create historical snapshot
    await createVulnerabilitySnapshot(rolloverResults);
    
    // Update daily totals for trend analysis
    await updateDailyTotals();
    
    // Commit transaction
    await db.run('COMMIT');
    
  } catch (error) {
    // Rollback on error
    await db.run('ROLLBACK');
    throw error;
  }
  
  return updateSummary;
}
```

## User Interface Specifications

### Import Dialog

```html
<!-- CSV Import Modal -->
<div class="modal" id="importModal">
  <div class="modal-dialog modal-lg">
    <div class="modal-content">
      <div class="modal-header">
        <h5>Import Vulnerability Scan</h5>
      </div>
      <div class="modal-body">
        <!-- File Selection -->
        <div class="mb-3">
          <label class="form-label">Select CSV File</label>
          <input type="file" class="form-control" accept=".csv" id="csvFile">
          <div class="form-text">Supported formats: Tenable, Qualys, OpenVAS (max 100MB)</div>
        </div>
        
        <!-- Import Options -->
        <div class="mb-3">
          <div class="form-check">
            <input class="form-check-input" type="checkbox" id="backupBeforeImport" checked>
            <label class="form-check-label">Create backup before import</label>
          </div>
          <div class="form-check">
            <input class="form-check-input" type="checkbox" id="validateOnly">
            <label class="form-check-label">Validate only (don't import)</label>
          </div>
        </div>
        
        <!-- Progress Indicator -->
        <div class="progress d-none" id="importProgress">
          <div class="progress-bar" role="progressbar"></div>
        </div>
        
        <!-- Results Summary -->
        <div class="alert alert-info d-none" id="importResults">
          <h6>Import Summary</h6>
          <ul class="mb-0" id="resultsList"></ul>
        </div>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancel</button>
        <button type="button" class="btn btn-primary" id="startImport">Import</button>
      </div>
    </div>
  </div>
</div>
```

### Progress Feedback

```javascript
class ImportProgressTracker {
  constructor(modalId) {
    this.modal = document.getElementById(modalId);
    this.progressBar = this.modal.querySelector('.progress-bar');
    this.resultsContainer = this.modal.querySelector('#importResults');
  }
  
  updateProgress(percentage, message) {
    this.progressBar.style.width = `${percentage}%`;
    this.progressBar.textContent = message;
  }
  
  showResults(summary) {
    const resultsList = this.modal.querySelector('#resultsList');
    resultsList.innerHTML = `
      <li><strong>New:</strong> ${summary.new} vulnerabilities</li>
      <li><strong>Updated:</strong> ${summary.updated} vulnerabilities</li>
      <li><strong>Resolved:</strong> ${summary.resolved} vulnerabilities</li>
      ${summary.errors.length > 0 ? `<li><strong>Errors:</strong> ${summary.errors.length}</li>` : ''}
    `;
    
    this.resultsContainer.classList.remove('d-none');
  }
}
```

## Testing Strategy

### Unit Tests

```javascript
describe('Vulnerability Import', () => {
  describe('CSV Parsing', () => {
    test('should parse valid Tenable CSV format', async () => {
      const csvContent = 'hostname,cve,severity,description\nserver01,CVE-2023-1234,High,Buffer overflow';
      const result = await parseCsvContent(csvContent);
      expect(result).toHaveLength(1);
      expect(result[0].hostname).toBe('server01');
    });
    
    test('should handle malformed CSV gracefully', async () => {
      const csvContent = 'hostname,cve\nserver01'; // Missing field
      const result = await parseCsvContent(csvContent);
      expect(result.errors).toBeDefined();
    });
  });
  
  describe('Deduplication', () => {
    test('should generate consistent dedup keys', () => {
      const vuln = { hostname: 'Server01.domain.com', cve: 'CVE-2023-1234' };
      const key1 = generateDedupKeys(vuln).dedupKey;
      const key2 = generateDedupKeys(vuln).dedupKey;
      expect(key1).toBe(key2);
      expect(key1).toBe('server01|CVE-2023-1234');
    });
    
    test('should use fallback key when CVE missing', () => {
      const vuln = { hostname: 'server01', plugin_id: '12345', description: 'Test vulnerability' };
      const result = generateDedupKeys(vuln);
      expect(result.keyType).toBe('hostname_plugin_desc');
      expect(result.dedupKey).toContain('server01|12345|');
    });
  });
  
  describe('Rollover Logic', () => {
    test('should identify new vulnerabilities', async () => {
      const newData = [{ dedupKey: 'server01|CVE-2023-1234', severity: 'High' }];
      const results = await performRolloverAnalysis(newData);
      expect(results.new).toHaveLength(1);
      expect(results.new[0].status).toBe('NEW');
    });
    
    test('should identify resolved vulnerabilities', async () => {
      // Mock existing vulnerability that's not in new data
      const results = await performRolloverAnalysis([]);
      expect(results.resolved.length).toBeGreaterThan(0);
    });
  });
});
```

### Integration Tests

```javascript
describe('Import Integration', () => {
  test('should complete full import workflow', async () => {
    const testFile = createTestCSVFile();
    const results = await processVulnerabilityImport(testFile);
    
    expect(results.success).toBe(true);
    expect(results.summary.new).toBeGreaterThan(0);
    
    // Verify database was updated
    const count = await db.get('SELECT COUNT(*) as count FROM vulnerabilities_current');
    expect(count.count).toBeGreaterThan(0);
  });
  
  test('should handle large file imports', async () => {
    const largeFile = createLargeTestCSVFile(10000); // 10k records
    const startTime = Date.now();
    
    const results = await processVulnerabilityImport(largeFile);
    const duration = Date.now() - startTime;
    
    expect(duration).toBeLessThan(30000); // <30 seconds
    expect(results.success).toBe(true);
  });
});
```

## Error Handling

### Validation Errors

```javascript
class ImportValidationError extends Error {
  constructor(row, field, value, expected) {
    super(`Invalid ${field} in row ${row}: "${value}" (expected: ${expected})`);
    this.name = 'ImportValidationError';
    this.row = row;
    this.field = field;
    this.value = value;
    this.expected = expected;
  }
}

function validateVulnerabilityRow(row, index) {
  const errors = [];
  
  // Required fields
  if (!row.hostname?.trim()) {
    errors.push(new ImportValidationError(index, 'hostname', row.hostname, 'non-empty string'));
  }
  
  if (!row.description?.trim()) {
    errors.push(new ImportValidationError(index, 'description', row.description, 'non-empty string'));
  }
  
  // Format validation
  if (row.cve && !isValidCVEFormat(row.cve)) {
    errors.push(new ImportValidationError(index, 'cve', row.cve, 'CVE-YYYY-NNNN format'));
  }
  
  if (row.severity && !isValidSeverity(row.severity)) {
    errors.push(new ImportValidationError(index, 'severity', row.severity, 'Critical|High|Medium|Low|Info'));
  }
  
  return errors;
}
```

## Performance Monitoring

```javascript
class ImportPerformanceMonitor {
  constructor() {
    this.metrics = {
      parseTime: 0,
      validationTime: 0,
      rolloverTime: 0,
      databaseTime: 0,
      totalTime: 0,
      recordsProcessed: 0,
      recordsPerSecond: 0
    };
  }
  
  startTimer(operation) {
    this[`${operation}Start`] = Date.now();
  }
  
  endTimer(operation) {
    const duration = Date.now() - this[`${operation}Start`];
    this.metrics[`${operation}Time`] = duration;
  }
  
  calculateMetrics() {
    this.metrics.recordsPerSecond = this.metrics.recordsProcessed / (this.metrics.totalTime / 1000);
    
    // Log performance metrics
    console.log('Import Performance Metrics:', this.metrics);
    
    // Alert if performance is below threshold
    if (this.metrics.recordsPerSecond < 100) {
      console.warn('Import performance below threshold:', this.metrics.recordsPerSecond, 'records/sec');
    }
  }
}
```

This specification provides comprehensive coverage of the vulnerability import feature, ensuring reliable, performant, and user-friendly CSV processing with intelligent deduplication and rollover analysis.