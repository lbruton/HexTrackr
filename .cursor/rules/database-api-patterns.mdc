---
globs: *.js
---

# Database and API Patterns for HexTrackr

## Database Schema Evolution

### SQLite Schema Management
All schema changes must be idempotent ALTER statements in [server.js](mdc:server.js):

```javascript
// ✅ Correct - Idempotent schema changes
db.run(`ALTER TABLE tickets ADD COLUMN priority TEXT DEFAULT 'Medium'`);
db.run(`ALTER TABLE vulnerabilities_current ADD COLUMN last_updated TEXT`);

// ❌ Wrong - Non-idempotent changes
db.run(`CREATE TABLE new_table (id INTEGER PRIMARY KEY)`);
```

### Database Initialization
Use [scripts/init-database.js](mdc:scripts/init-database.js) for initial setup:

```javascript
// Database connection pattern
const dbPath = path.join(__dirname, "..", "data", "hextrackr.db");
const db = new sqlite3.Database(dbPath, (err) => {
    if (err) {
        console.error("Error opening database:", err.message);
        return;
    }
    console.log("Connected to SQLite database");
});
```

## API Endpoint Patterns

### Standard Response Format
```javascript
// Success response
res.json({ 
    success: true, 
    data: result,
    message: "Operation completed successfully"
});

// Error response
res.status(400).json({ 
    success: false, 
    error: "Invalid input data",
    code: "INVALID_INPUT"
});
```

### Vulnerability API Endpoints
```javascript
// GET /api/vulnerabilities - List with pagination
app.get('/api/vulnerabilities', async (req, res) => {
    try {
        const { page = 1, limit = 50, search = '' } = req.query;
        const offset = (page - 1) * limit;
        
        const vulnerabilities = await getVulnerabilities(offset, limit, search);
        const total = await getVulnerabilityCount(search);
        
        res.json({
            success: true,
            data: vulnerabilities,
            pagination: {
                page: parseInt(page),
                limit: parseInt(limit),
                total: total,
                pages: Math.ceil(total / limit)
            }
        });
    } catch (error) {
        console.error("Error fetching vulnerabilities:", error);
        res.status(500).json({ success: false, error: "Internal server error" });
    }
});

// POST /api/vulnerabilities/import - CSV import
app.post('/api/vulnerabilities/import', upload.single('file'), async (req, res) => {
    try {
        if (!req.file) {
            return res.status(400).json({ success: false, error: "No file uploaded" });
        }
        
        const result = await processVulnerabilityImport(req.file.path);
        res.json({ success: true, data: result });
    } catch (error) {
        console.error("Import error:", error);
        res.status(500).json({ success: false, error: "Import failed" });
    }
});
```

### Ticket API Endpoints
```javascript
// GET /api/tickets - List tickets
app.get('/api/tickets', async (req, res) => {
    try {
        const tickets = await getTickets();
        res.json({ success: true, data: tickets });
    } catch (error) {
        console.error("Error fetching tickets:", error);
        res.status(500).json({ success: false, error: "Internal server error" });
    }
});

// POST /api/tickets - Create ticket
app.post('/api/tickets', async (req, res) => {
    try {
        const ticketData = req.body;
        validateTicketData(ticketData);
        
        const ticket = await createTicket(ticketData);
        res.json({ success: true, data: ticket });
    } catch (error) {
        console.error("Error creating ticket:", error);
        res.status(400).json({ success: false, error: error.message });
    }
});
```

## Database Query Patterns

### Parameterized Queries
```javascript
// ✅ Correct - Use prepared statements
function getVulnerabilities(offset, limit, search) {
    return new Promise((resolve, reject) => {
        const query = `
            SELECT * FROM vulnerabilities_current 
            WHERE hostname LIKE ? OR description LIKE ?
            ORDER BY last_updated DESC
            LIMIT ? OFFSET ?
        `;
        const searchTerm = `%${search}%`;
        
        db.all(query, [searchTerm, searchTerm, limit, offset], (err, rows) => {
            if (err) reject(err);
            else resolve(rows);
        });
    });
}

// ❌ Wrong - String concatenation
function getVulnerabilitiesBad(offset, limit, search) {
    const query = `SELECT * FROM vulnerabilities_current WHERE hostname LIKE '%${search}%'`;
    // This is vulnerable to SQL injection
}
```

### Transaction Patterns
```javascript
// Use transactions for multiple related operations
function processVulnerabilityRollover(vulnerabilities) {
    return new Promise((resolve, reject) => {
        db.serialize(() => {
            db.run("BEGIN TRANSACTION");
            
            // Process each vulnerability sequentially
            for (const vuln of vulnerabilities) {
                db.run(`
                    INSERT OR REPLACE INTO vulnerabilities_current 
                    (hostname, cve, plugin_id, description, severity, last_updated)
                    VALUES (?, ?, ?, ?, ?, ?)
                `, [vuln.hostname, vuln.cve, vuln.plugin_id, vuln.description, vuln.severity, new Date().toISOString()]);
            }
            
            db.run("COMMIT", (err) => {
                if (err) {
                    db.run("ROLLBACK");
                    reject(err);
                } else {
                    resolve({ success: true, processed: vulnerabilities.length });
                }
            });
        });
    });
}
```

## Data Processing Patterns

### Vulnerability Rollover Logic
```javascript
// Sequential processing to prevent race conditions
async function processVulnerabilityRowsWithRollover(rows) {
    const results = [];
    
    // Process rows sequentially, not in parallel
    for (const row of rows) {
        try {
            const processed = await processVulnerabilityRow(row);
            results.push(processed);
        } catch (error) {
            console.error("Error processing row:", error);
            results.push({ error: error.message, row: row });
        }
    }
    
    return results;
}

function processVulnerabilityRow(row) {
    // Normalize hostname for consistent deduplication
    const normalizedHostname = normalizeHostname(row.hostname);
    
    // Create dedup key
    const dedupKey = row.cve 
        ? `${normalizedHostname}_${row.cve}`
        : `${normalizedHostname}_${row.plugin_id}_${row.description}`;
    
    return {
        ...row,
        normalized_hostname: normalizedHostname,
        dedup_key: dedupKey,
        processed_at: new Date().toISOString()
    };
}
```

### JSON Data Handling
```javascript
// Store complex data as JSON strings
function createTicket(ticketData) {
    return new Promise((resolve, reject) => {
        const devicesJson = JSON.stringify(ticketData.devices || []);
        const attachmentsJson = JSON.stringify(ticketData.attachments || []);
        
        db.run(`
            INSERT INTO tickets (id, location, devices, description, urgency, category, status, assigned_to, created_date, attachments)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `, [
            ticketData.id,
            ticketData.location,
            devicesJson,
            ticketData.description,
            ticketData.urgency,
            ticketData.category,
            ticketData.status || 'Open',
            ticketData.assigned_to,
            ticketData.created_date || new Date().toISOString(),
            attachmentsJson
        ], function(err) {
            if (err) reject(err);
            else resolve({ id: this.lastID, ...ticketData });
        });
    });
}

// Parse JSON data when retrieving
function getTickets() {
    return new Promise((resolve, reject) => {
        db.all("SELECT * FROM tickets ORDER BY created_date DESC", (err, rows) => {
            if (err) {
                reject(err);
            } else {
                // Parse JSON fields
                const tickets = rows.map(row => ({
                    ...row,
                    devices: JSON.parse(row.devices || '[]'),
                    attachments: JSON.parse(row.attachments || '[]')
                }));
                resolve(tickets);
            }
        });
    });
}
```

## Error Handling Patterns

### Database Error Handling
```javascript
// Consistent error handling for database operations
function handleDatabaseError(error, operation) {
    console.error(`Database error in ${operation}:`, error);
    
    if (error.code === 'SQLITE_CONSTRAINT') {
        return { success: false, error: "Data constraint violation", code: "CONSTRAINT_ERROR" };
    } else if (error.code === 'SQLITE_BUSY') {
        return { success: false, error: "Database is busy, please try again", code: "BUSY_ERROR" };
    } else {
        return { success: false, error: "Database operation failed", code: "DB_ERROR" };
    }
}
```

### API Error Handling
```javascript
// Centralized error handling middleware
app.use((error, req, res, next) => {
    console.error("API Error:", error);
    
    if (error.code === 'LIMIT_FILE_SIZE') {
        return res.status(400).json({
            success: false,
            error: "File too large. Maximum size is 100MB.",
            code: "FILE_TOO_LARGE"
        });
    }
    
    res.status(500).json({
        success: false,
        error: "Internal server error",
        code: "INTERNAL_ERROR"
    });
});
```

## Performance Patterns

### Pagination Implementation
```javascript
// Efficient pagination with count
async function getPaginatedData(table, page = 1, limit = 50, search = '') {
    const offset = (page - 1) * limit;
    
    // Get total count
    const countQuery = `SELECT COUNT(*) as total FROM ${table} WHERE hostname LIKE ?`;
    const total = await new Promise((resolve, reject) => {
        db.get(countQuery, [`%${search}%`], (err, row) => {
            if (err) reject(err);
            else resolve(row.total);
        });
    });
    
    // Get paginated data
    const dataQuery = `
        SELECT * FROM ${table} 
        WHERE hostname LIKE ? 
        ORDER BY last_updated DESC 
        LIMIT ? OFFSET ?
    `;
    const data = await new Promise((resolve, reject) => {
        db.all(dataQuery, [`%${search}%`, limit, offset], (err, rows) => {
            if (err) reject(err);
            else resolve(rows);
        });
    });
    
    return {
        data,
        pagination: {
            page: parseInt(page),
            limit: parseInt(limit),
            total: total,
            pages: Math.ceil(total / limit)
        }
    };
}
```

### Memory Management
```javascript
// Always clean up temporary files
function processFileUpload(filePath) {
    return new Promise(async (resolve, reject) => {
        try {
            const result = await processFile(filePath);
            resolve(result);
        } catch (error) {
            reject(error);
        } finally {
            // Always clean up temp file
            fs.unlink(filePath, (err) => {
                if (err) console.error("Error deleting temp file:", err);
            });
        }
    });
}
```